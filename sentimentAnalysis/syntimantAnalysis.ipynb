{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "57a185b4-0373-430a-a273-d89c09686ef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is for testing \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a7d1e826-4226-45b4-afca-0dafdf802973",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def readFiles(filePath):\n",
    "    with open(filePath,\"r\") as f:\n",
    "        splitDot=f.read().split(\".\")\n",
    "        final=[x.split(\"?\") for x in splitDot]\n",
    "        finalList=[]\n",
    "        for x in final:\n",
    "            for y in x:\n",
    "                y=y.replace(\"\\n\",\"\")\n",
    "                finalList.append(y)\n",
    "    return finalList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f7abd339-20ef-4107-9dc3-14119885cc16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def findAllFiles(path):\n",
    "    filesName=[]\n",
    "    for x,y,z  in os.walk(path):\n",
    "          for file in z:\n",
    "                name=x+\"/\"+file\n",
    "                filesName.append(name)\n",
    "    return filesName\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "931fba8d-5684-4f54-a3c4-a5402d73717a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000\n"
     ]
    }
   ],
   "source": [
    "negFileList=findAllFiles(\"txt_sentoken/neg\")\n",
    "posFileList=findAllFiles(\"txt_sentoken/pos\")\n",
    "print(len(negFileList),len(posFileList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d3052ede-f66e-429e-9451-a2225a337026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000\n"
     ]
    }
   ],
   "source": [
    "positivefilesData=[]\n",
    "negFileListData=[]\n",
    "for x in posFileList:\n",
    "    positivefilesData.append(readFiles(x))\n",
    "for x in negFileList:\n",
    "    negFileListData.append(readFiles(x))\n",
    "                           \n",
    "print(len(positivefilesData),len(negFileListData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "361542d6-0d8b-4136-aeef-e1afbe18accd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i can hear the question already ', ' what on earth do these two movies have in common ', ' to most people , not a lot , except that both are by renowned directors ', ' as i saw them , however , both movies have flawed romantic scripts wrapped in distinctive packaging of lavish visuals musical numbers ', ' but oh , how differently the packages affect their films ', ' while \" everyone\\'s \" production numbers make an otherwise ordinary woody tale something special , jane campion\\'s imaginative visuals only serve to emphasize how pompous and uninvolving laura jones\\' script is ', ' i left \" everyone says i love you \" not remembering a lot about who loved whom , but its infectious happiness put a grin on my face ', ' i left \" the portrait of a lady \" not remembering a lot about who loved whom , and i could have cared less ', '  \" everyone \" features nothing allen hasn\\'t done before storywise ', ' woody is again desperately in love with a beautiful woman ( roberts ) , and against the odds they manage to click for awhile before allen is left wondering what went wrong--again ', ' similar situations happen to his family and friends ', ' some of the more outlandish comedy scenes even hark back to his \" early , funny \" films ', ' the scenes between tim roth and drew barrymore could have come out of \" take the money and run , \" his directorial debut ', ' however , nothing allen has ever done prepared me for this one-of-a-kind display of sheer good spirits ', \" in fact , in this movie , the feeling itself is what's most important \", ' yes , the movie would have been better--among his very best , i think--if it had a meatier story ', ' but what it lacks in substance it makes up for in feeling ', ' and what better way to express feeling than through music ', ' love is often best expressed in a song , and the numbers the cast break into here cut straight to the heart ', ' some are a tad too goofy , such as the number where a lot of ghosts prance around in a funeral parlor , but i admired allen for even putting them in there ', ' it also helps that as usual , allen has a top-flight cast working with him ', ' their singing voices range from quite good ( goldie hawn ) to not quite good ( allen ) to literally unlistenable ( barrymore , whose real voice was dubbed by a professional ) ', ' but while their vocal abilities differ , all the actors do a great job of putting joy up there on the screen , and making it rub off on the audience ', ' granted , some people will simply never accept characters singing in movies , but for those attuned to it , this film should work wonders ', ' jane campion , too , has a top-flight cast working for her in \" portrait of a lady , \" too , but even their considerable skills can do nothing to keep the film from being a stilted , virtually lifeless mess , albeit a visually interesting one ', ' campion and her cinematographer stuart dryburgh come up with a great variety of eye-filling images that linger in the mind ', \" unfortunately , what didn't linger in the mind for me was the story the visuals were supposed to be reflecting \", ' i remember very well shots of a train with its light beaming and shots of men vanishing around nicole kidman , but i can remember very little of what happened between all these people ', \" even worse , i don't find myself feeling bad that i've forgotten \", ' the problem , i think , lies not with the cast , which seemed to be trying very hard for the material ', \" it was the script that couldn't convince me to care about anyone \", ' the characters were putting out all kinds of emotion , but i found no reason to connect with any of them ', ' i understood that the story was about cold , emotionally vacant characters , but for me to care about them , i have to identify with them somehow and want them to inject feeling into their lives ', \" jones' script never simply gave me that opportunity \", ' in the end , it almost seemed as if campion was trying to inject some life of her own into the proceedings with her visual flourishes ', ' unfortunately , as she kept painting these dazzling pictures , they only served to push me further away from the material and remind me that there was no connection between me and the film ', \" in the end , the movie's one strength ended up hurting it \", ' so here we have two films with pretty uninteresting plots , and yet i was able to truly enjoy one of them ', ' why ', ' with both films , my head cared about neither story , but only \" everyone says i love you \" was able to make my heart sing ', ' ']\n"
     ]
    }
   ],
   "source": [
    "print(positivefilesData[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "71a4f0af-d207-45c6-ba0e-df54d2fa7f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(stringList):\n",
    "    dataToSend=[]\n",
    "    symbols=[]\n",
    "    with open(\"symbols.txt\",\"r\") as f:\n",
    "        symbols=f.read().split()\n",
    "    for rows in stringList:\n",
    "        rowData=[]\n",
    "        for data in rows:\n",
    "            for l in symbols:\n",
    "                data=data.replace(l,\"\")\n",
    "            string=data.split(\" \")\n",
    "            for x in string:\n",
    "                if x != '':\n",
    "                    rowData.append(x)\n",
    "        dataToSend.append(rowData)\n",
    "                    \n",
    "    return dataToSend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6c2fce3f-1a0d-4f8c-a7b7-34a69477b8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/nk/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7e8a4591-f522-46d0-a4d0-e19a8c62b370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords \n",
    "# stopwords_english = stopwords.words('english') \n",
    "# with open(\"./stopWord.txt\",\"w\") as f:\n",
    "#     string=\"\"\n",
    "#     for x in stopwords_english:\n",
    "#         string+=x+\"\\n\"\n",
    "#     print(string)\n",
    "#     f.write(string)\n",
    "def removeStopWord(tokenizedData):\n",
    "    with open(\"stopWord.txt\",\"r\") as f:\n",
    "        stopWord=f.read().split(\"\\n\")\n",
    "        dataWithoutStopWord=[]\n",
    "        for row in tokenizedData:\n",
    "            data=[x for x in row if x not in stopWord]\n",
    "            dataWithoutStopWord.append(data)  \n",
    "        return dataWithoutStopWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "253fa3b1-8a5b-486b-a08f-5098b7a95b58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "negtoken=tokenizer(positivefilesData)\n",
    "postoken=tokenizer(negFileListData)\n",
    "poswithoutStopWord=removeStopWord(postoken)\n",
    "negwithoutStopWord=removeStopWord(negtoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cf9fc97e-36f6-4478-a3a9-ab4bca209813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer ,LancasterStemmer\n",
    "porter=PorterStemmer()\n",
    "lancaster=LancasterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "23f4b863-ee98-466e-ba2e-77cab3ffafab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def streamingWord(listOfWord):\n",
    "    dataToSend=[]\n",
    "    for row in listOfWord:\n",
    "        rowData= [porter.stem(words) for words in row]\n",
    "        dataToSend.append(rowData)\n",
    "    return dataToSend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "74cbf8a6-2030-442c-ac1a-d88c79f9a6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hear', 'question', 'alreadi', 'earth', 'two', 'movi', 'common', 'peopl', 'lot', 'except', 'renown', 'director', 'saw', 'howev', 'movi', 'flaw', 'romant', 'script', 'wrap', 'distinct', 'packag', 'lavish', 'visual', 'music', 'number', 'oh', 'differ', 'packag', 'affect', 'film', \"everyone'\", 'product', 'number', 'make', 'otherwis', 'ordinari', 'woodi', 'tale', 'someth', 'special', 'jane', \"campion'\", 'imagin', 'visual', 'serv', 'emphas', 'pompou', 'uninvolv', 'laura', \"jones'\", 'script', 'left', 'everyon', 'say', 'love', 'rememb', 'lot', 'love', 'infecti', 'happi', 'put', 'grin', 'face', 'left', 'portrait', 'ladi', 'rememb', 'lot', 'love', 'could', 'care', 'less', 'everyon', 'featur', 'noth', 'allen', 'done', 'storywis', 'woodi', 'desper', 'love', 'beauti', 'woman', 'robert', 'odd', 'manag', 'click', 'awhil', 'allen', 'left', 'wonder', 'went', 'wrongagain', 'similar', 'situat', 'happen', 'famili', 'friend', 'outlandish', 'comedi', 'scene', 'even', 'hark', 'back', 'earli', 'funni', 'film', 'scene', 'tim', 'roth', 'drew', 'barrymor', 'could', 'come', 'take', 'money', 'run', 'directori', 'debut', 'howev', 'noth', 'allen', 'ever', 'done', 'prepar', 'oneofakind', 'display', 'sheer', 'good', 'spirit', 'fact', 'movi', 'feel', \"what'\", 'import', 'ye', 'movi', 'would', 'betteramong', 'best', 'thinkif', 'meatier', 'stori', 'lack', 'substanc', 'make', 'feel', 'better', 'way', 'express', 'feel', 'music', 'love', 'often', 'best', 'express', 'song', 'number', 'cast', 'break', 'cut', 'straight', 'heart', 'tad', 'goofi', 'number', 'lot', 'ghost', 'pranc', 'around', 'funer', 'parlor', 'admir', 'allen', 'even', 'put', 'also', 'help', 'usual', 'allen', 'topflight', 'cast', 'work', 'sing', 'voic', 'rang', 'quit', 'good', 'goldi', 'hawn', 'quit', 'good', 'allen', 'liter', 'unlisten', 'barrymor', 'whose', 'real', 'voic', 'dub', 'profession', 'vocal', 'abil', 'differ', 'actor', 'great', 'job', 'put', 'joy', 'screen', 'make', 'rub', 'audienc', 'grant', 'peopl', 'simpli', 'never', 'accept', 'charact', 'sing', 'movi', 'attun', 'film', 'work', 'wonder', 'jane', 'campion', 'topflight', 'cast', 'work', 'portrait', 'ladi', 'even', 'consider', 'skill', 'noth', 'keep', 'film', 'stilt', 'virtual', 'lifeless', 'mess', 'albeit', 'visual', 'interest', 'one', 'campion', 'cinematograph', 'stuart', 'dryburgh', 'come', 'great', 'varieti', 'eyefil', 'imag', 'linger', 'mind', 'unfortun', 'linger', 'mind', 'stori', 'visual', 'suppos', 'reflect', 'rememb', 'well', 'shot', 'train', 'light', 'beam', 'shot', 'men', 'vanish', 'around', 'nicol', 'kidman', 'rememb', 'littl', 'happen', 'peopl', 'even', 'wors', 'find', 'feel', 'bad', \"i'v\", 'forgotten', 'problem', 'think', 'lie', 'cast', 'seem', 'tri', 'hard', 'materi', 'script', 'convinc', 'care', 'anyon', 'charact', 'put', 'kind', 'emot', 'found', 'reason', 'connect', 'understood', 'stori', 'cold', 'emot', 'vacant', 'charact', 'care', 'identifi', 'somehow', 'want', 'inject', 'feel', 'live', \"jones'\", 'script', 'never', 'simpli', 'gave', 'opportun', 'end', 'almost', 'seem', 'campion', 'tri', 'inject', 'life', 'proceed', 'visual', 'flourish', 'unfortun', 'kept', 'paint', 'dazzl', 'pictur', 'serv', 'push', 'away', 'materi', 'remind', 'connect', 'film', 'end', \"movie'\", 'one', 'strength', 'end', 'hurt', 'two', 'film', 'pretti', 'uninterest', 'plot', 'yet', 'abl', 'truli', 'enjoy', 'one', 'film', 'head', 'care', 'neither', 'stori', 'everyon', 'say', 'love', 'abl', 'make', 'heart', 'sing']\n",
      "['rememb', 'tom', 'cruis', 'brian', 'brown', 'rival', 'bartend', 'juggl', 'bottl', 'booz', 'cocktail', 'rememb', 'stupid', 'look', 'rememb', 'scantilyclad', 'dancer', 'flashdanc', 'get', 'dous', 'bucket', 'water', 'well', 'coyot', 'ugli', 'film', 'five', 'better', 'six', 'better', 'count', 'john', 'goodman', 'sinc', 'piper', 'perado', 'maria', 'bello', 'tyra', 'bank', 'melani', 'lynskey', 'izabella', 'miko', 'absolut', 'spin', 'jiggl', 'thing', 'pour', 'pitcher', 'perrier', 'seminak', 'torso', 'goodman', 'flip', 'jim', 'beam', 'wear', 'anyth', 'particularli', 'risqu', 'film', 'get', 'bar', 'start', 'gyrat', 'rest', 'central', \"character'\", 'love', 'interest', 'play', 'australian', 'actor', 'name', 'adam', 'garcia', 'prove', 'get', 'bar', 'start', 'shimmi', 'along', 'rest', 'seem', 'start', 'life', \"victoria'\", 'secret', 'photo', 'shoot', 'quickli', 'deterior', 'one', 'heck', 'embarrass', 'movi', 'violet', 'perado', 'south', 'amboy', 'hope', 'tri', 'make', 'big', 'songwrit', 'welder', 'new', 'jack', 'citi', 'na', 'come', 'fob', 'music', \"producer'\", 'receptionist', 'scorn', 'apart', 'rob', 'hour', 'touch', 'chinatown', 'like', 'mother', 'get', 'stage', 'fright', 'whenev', 'tri', 'open', 'mike', 'night', 'thing', 'see', 'trio', 'babealici', 'barkeep', 'thumb', 'stack', 'allnight', 'diner', 'violet', 'simpli', 'check', 'bar', 'call', 'coyot', 'ugli', 'lil', 'bello', 'nononsens', 'owner', 'agre', 'give', 'violet', 'audit', 'violet', 'blow', 'still', 'lil', 'give', 'violet', 'anoth', 'chanc', 'riot', 'break', 'riot', 'order', 'day', \"'ugly'\", 'sinc', 'staff', 'relentless', 'flaunt', 'sexual', 'ware', 'flambe', 'bar', 'soak', 'patron', 'diet', 'spritethi', 'certifi', 'behavior', 'case', 'mention', 'violet', 'success', 'subdu', 'crowd', 'sing', 'along', \"blondie'\", 'one', 'way', 'anoth', 'jukebox', 'hire', 'cure', 'sinc', 'littl', 'episod', 'give', 'confid', 'sing', 'amateur', 'talent', 'contest', 'dad', 'goodman', 'junk', 'foodeat', 'laundryimpair', 'toll', 'collector', 'come', 'see', 'proud', 'punch', 'end']\n"
     ]
    }
   ],
   "source": [
    "negRootWord=streamingWord(negwithoutStopWord)\n",
    "posRootWord=streamingWord(poswithoutStopWord)\n",
    "print(negRootWord[1])\n",
    "print(posRootWord[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0153c97d-2adc-454f-8200-b6ec991f13ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(tweet):\n",
    "    data=streamingWord(removeStopWord(tokenizer(tweet)))\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7303625b-9620-4f53-9b5c-f24bfaabca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_frequency(tweets,lables):\n",
    "    freq={}\n",
    "    for lable ,tweet in zip(lables,tweets):\n",
    "        for tp,row in zip(lable,processData(tweet)):\n",
    "            for data in row:\n",
    "                pair=(data,tp)\n",
    "                if pair in freq:\n",
    "                    freq[pair]+=1\n",
    "                else:\n",
    "                    freq[pair]=1\n",
    "    return freq\n",
    "    \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a926c0b4-faac-47c9-ad3b-a78af374736c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66273cd3-077a-4f01-8153-3c8b43b6c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "66fefbc2-ad0a-4985-8894-d986c85e33e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine data\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "95c99172-354d-4e18-848f-0bab9d52fd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 2000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lables=np.array([np.ones(len(positivefilesData)),np.zeros(len(negFileListData))],dtype=np.int32)\n",
    "tweets=np.array([positivefilesData,negFileListData],dtype=type(list))\n",
    "print(lables.size,tweets.size)\n",
    "               \n",
    "# dataAfter=processData(positivefilesData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "36c5418a-6cbb-4355-89ce-508d2030ba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq=build_frequency(tweets,lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27e8ec6-7350-4f1c-972d-1eb580b9d0b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4eff1280-fbfb-46f5-931b-9bbc924bc45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('one', 1) 3007\n",
      "('like', 1) 1947\n",
      "('see', 1) 1233\n",
      "('make', 1) 1649\n",
      "('get', 1) 1502\n",
      "('good', 1) 1226\n",
      "('charact', 1) 1969\n",
      "('movi', 1) 3018\n",
      "('scene', 1) 1347\n",
      "('film', 1) 5818\n",
      "('time', 1) 1523\n",
      "('play', 1) 1227\n",
      "('even', 1) 1198\n",
      "('stori', 1) 1324\n",
      "('way', 1) 1024\n",
      "('also', 1) 1200\n",
      "('much', 1) 1027\n",
      "('like', 0) 2049\n",
      "('bad', 0) 1026\n",
      "('film', 0) 4702\n",
      "('scene', 0) 1288\n",
      "('play', 0) 1133\n",
      "('get', 0) 1682\n",
      "('movi', 0) 3601\n",
      "('even', 0) 1402\n",
      "('make', 0) 1502\n",
      "('one', 0) 2688\n",
      "('would', 0) 1049\n",
      "('look', 0) 1017\n",
      "('charact', 0) 1753\n",
      "('good', 0) 1153\n",
      "('time', 0) 1376\n"
     ]
    }
   ],
   "source": [
    "for x in freq:\n",
    "    if freq[x] > 1000:\n",
    "        print(x,freq[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2f1a758d-b254-4353-ac2d-b3055880a60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['see', 1233, 963], ['like', 1947, 2049], ['see', 1233, 963], ['look', 809, 1017], ['good', 1226, 1153], ['movi', 3018, 3601], ['scene', 1347, 1288]]\n"
     ]
    }
   ],
   "source": [
    "key=['see','like','see','look','good','movi','scene']\n",
    "data=[]\n",
    "\n",
    "for word in key:\n",
    "    pos=0\n",
    "    neg=0\n",
    "    if (word,1) in freq:\n",
    "        pos=freq[(word,1)]\n",
    "    if (word,0) in freq:\n",
    "        neg=freq[(word,0)]\n",
    "    data.append([word,pos,neg])\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6abf2095-5e74-4e3e-8afc-4adf56ad3c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive=processData(positivefilesData)\n",
    "negative=processData(negFileListData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "34e16ed1-5d61-4ca9-bfe3-c963da4dcfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findUnique(listData):\n",
    "    data=set()\n",
    "    for x in listData:\n",
    "        data.add(x)\n",
    "    return list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "10cbfa8e-f8ee-4971-8488-8ebcb930a918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428\n",
      "['watch', 'mckenna', 'use', 'everyon', 'genr', \"tango'\", 'result', 'certain', 'lose', 'glass', 'last', 'instantli', 'delight', 'spread', 'deliv', 'dylan', 'platt', 'tone', 'rich', 'comedi', 'novak', 'perri', 'alreadi', 'constantli', 'obvious', 'humor', 'post', 'convinc', 'restor', 'ask', 'unpredict', 'lucki', 'bigger', 'park', 'point', 'impress', 'edgi', 'clever', 'suffer', 'romanticmistaken', 'perfect', 'adventur', 'weak', 'superb', 'true', 'trust', 'nonetheless', 'stick', 'gem', 'spark', 'gay', 'charl', 'scene', 'sharp', 'town', 'prove', 'practic', 'movi', 'unlik', 'stand', 'partner', 'would', 'spot', 'longer', 'along', 'one', 'steinberg', 'suppos', 'upcom', 'escap', 'affect', 'live', 'romant', 'charact', 'campbel', 'written', 'joke', 'film', 'wise', 'occurr', 'offend', 'star', 'go', 'someon', 'night', 'chandler', 'businessman', 'conflict', 'plain', 'keep', 'play', 'ironi', 'lead', 'build', 'idea', 'openli', 'could', 'dialogu', 'act', 'crude', 'rodney', 'object', 'light', 'meet', 'well', 'look', 'fight', 'becom', 'thing', 'deni', 'love', 'job', 'v', 'person', 'must', 'art', 'found', 'els', 'damon', 'audienc', 'flamboyantli', 'pure', 'usual', 'bit', 'ever', 'funni', 'hardli', 'alin', 'stay', 'perhap', 'two', 'vulgar', 'coupl', 'main', 'gladli', 'numer', 'fli', 'mutter', 'mind', \"charles'\", 'never', 'day', 'afraid', \"'s\", 'voic', 'horribl', 'complet', \"summer'\", 'rout', 'rumor', \"i'd\", \"can't\", 'snappi', 'feel', 'major', 'direct', 'time', 'santostefano', 'clumsi', 'base', 'focu', 'matthew', 'anyway', 'get', 'girl', 'swear', 'talk', 'kill', 'outsid', 'brosh', 'noth', 'assum', 'word', 'handl', 'oliv', 'shi', 'fact', 'mouth', 'oscar', 'come', 'south', 'mani', 'immedi', 'goe', 'anoth', 'like', 'meant', 'bore', 'line', 'vaccaro', 'phrase', 'disast', 'sens', 'wonder', 'show', 'clueless', 'popular', 'techniqu', 'present', 'know', 'set', 'smile', 'walk', 'content', 'see', \"he'\", 'peter', 'good', 'chicago', 'better', 'shock', 'suspici', 'mcdermott', 'tango', 'sensit', 'superbl', 'likabl', 'quit', 'done', 'element', 'fast', 'want', 'script', 'girlfriend', 'alway', 'newman', 'wellknown', 'laugh', 'architect', 'project', 'dull', 'take', 'great', 'plot', 'ami', 'origin', 'blow', 'close', 'neve', 'mill', 'outcom', 'fun', 'ident', 'either', 'cours', 'whatsoev', 'especi', 'make', 'enjoy', 'end', 'drama', 'seem', 'classic', 'hilari', 'assumpt', 'flat', 'uncut', 'drink', 'bottom', 'patrick', 'run', 'climax', 'first', 'three', 'tell', 'name', 'friend', 'think', 'horror', 'materi', 'sure', 'scream', 'share']\n"
     ]
    }
   ],
   "source": [
    "print(len(positive[0]))\n",
    "print(findUnique(positive[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "a34dffbc-19d4-4025-bd0e-d4350b23c0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posNegfreq(key,freq,tp=None):\n",
    "    data=np.array([0,0,0,0]) \n",
    "    for word in key:\n",
    "        pos=0\n",
    "        neg=0\n",
    "        if (word,1) in freq:\n",
    "            pos=freq[(word,1)]\n",
    "        if (word,0) in freq:\n",
    "            neg=freq[(word,0)]\n",
    "        data+=[0,pos,neg,0]\n",
    "    data[0]=1\n",
    "    data[-1]=tp\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "0f371e0c-d068-41f2-8178-16bc933c8b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "264db02f-65ea-47f2-9665-8ea230612cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "columns=['bias','positive','negative','sentiment']\n",
    "compliteData=[]\n",
    "for x in positive:\n",
    "    compliteData.append(posNegfreq(findUnique(x),freq,1))\n",
    "for y in negative:\n",
    "    compliteData.append(posNegfreq(findUnique(y),freq,0))\n",
    "print(len(compliteData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "43707964-da79-4e48-9c1d-e44772c1f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.DataFrame(compliteData,columns=columns,dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "786d2223-03f1-4ce9-a82d-d07f1267c37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>68204.0</td>\n",
       "      <td>63601.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>69304.0</td>\n",
       "      <td>66101.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>32681.0</td>\n",
       "      <td>29375.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>29789.0</td>\n",
       "      <td>28540.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>92631.0</td>\n",
       "      <td>88221.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      bias  positive  negative  sentiment\n",
       "1995   1.0   68204.0   63601.0        0.0\n",
       "1996   1.0   69304.0   66101.0        0.0\n",
       "1997   1.0   32681.0   29375.0        0.0\n",
       "1998   1.0   29789.0   28540.0        0.0\n",
       "1999   1.0   92631.0   88221.0        0.0"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "5598a0a3-0d41-4b02-aed9-99d005a9f9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "x_data=dataset[[\"bias\",\"positive\",\"negative\"]].values\n",
    "y_data=np.array(dataset[[\"sentiment\"]].values).reshape(-1)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "909e4a5f-294a-4838-85d4-53bd505e0baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class LogisticRegression:\n",
    "    def __init__(self,lr=0.0001,number_itr=1000):\n",
    "        self.lr=lr\n",
    "        self.itr=number_itr\n",
    "        self.weight=None;\n",
    "        self.bias=None;\n",
    "    def fit(self,X,y):\n",
    "      \n",
    "        number_sample,number_feature= X.shape\n",
    "        self.weight=np.zeros(number_feature)\n",
    "        self.bias=0\n",
    "#         Gradient desent\n",
    "        for _ in range(self.itr):\n",
    "            linearModel=np.dot(X,self.weight)+self.bias\n",
    "            y_predicted=self.sigmoid(linearModel)\n",
    "            dw= (1/number_sample)*(np.dot(X.T,(y_predicted-y)))\n",
    "            db=(1/number_sample)*np.sum (y_predicted-y)\n",
    "            self.weight-=dw*self.lr;\n",
    "            self.bias-=self.lr*db\n",
    "        \n",
    "    def predict(self,X):\n",
    "        print(X)\n",
    "        print(self.weight,self.bias)\n",
    "        linearModel=np.dot(X,self.weight) + self.bias\n",
    "        y_predict=self.sigmoid(linearModel)\n",
    "        print(y_predict)\n",
    "        y_predicted_cls=[1 if i>0.5 else 0 for i in y_predict]\n",
    "        return y_predicted_cls\n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "c0051d87-6c37-4b2b-b315-44e372627384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from LogisticRegression import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "b2f0adee-726b-4bac-9e08-28caa9e10bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_itr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      <no docstring>\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LogisticRegression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "2e5d6cc4-e530-4d0f-92f1-57934446b366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      /tmp/ipykernel_39487/2755136582.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=LogisticRegression(lr=0.001,number_itr=1000)\n",
    "model.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "970c57eb-17bf-4162-b774-13497f3cbaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39487/2755136582.py:31: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "model.fit(X=x_data,y=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "a5af8d07-442b-4288-9f2d-e2b29e010f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 42.0, 42.0], [1.0, 2681.0, 29375.0]]\n",
      "[-1.24587488e-02  3.76911282e+02 -3.74426831e+02] -0.012458748798643386\n",
      "[1. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39487/2755136582.py:31: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 0]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[1.0,0042.0,42.0],[1.0,2681.0,29375.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb03f819-ccba-4e44-b1bf-8c52ab94ba22",
   "metadata": {},
   "source": [
    "# Starting NaveBayes Classification For syntiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "a25b1928-3cd6-4c98-a0e8-9844f7f6e597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postive Negative Frequency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "d5dc29b3-3ab9-4fce-9fc0-7622e57a0105",
   "metadata": {},
   "outputs": [],
   "source": [
    "posNeg=freq.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "dcf16b5b-2ffa-4e7c-87b3-8f68ceffe50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findTotel(posNeg,sentiment):\n",
    "    count=0\n",
    "    for x in posNeg:\n",
    "        if x[1]==sentiment:\n",
    "            count+=posNeg[x]\n",
    "    return count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "80c5da77-5f25-456f-88c7-111f5a8d1396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330323\n",
      "371030\n"
     ]
    }
   ],
   "source": [
    "totelPos=findTotel(freq,1)\n",
    "totelNeg=findTotel(freq,0)\n",
    "print(totelNeg)\n",
    "print(totelPos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "12543a54-e261-4fa3-a11e-e0882eac835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making pridiction frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "fbf3cd94-ec68-44fb-9d1a-59c458b9a714",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in posNeg:\n",
    "    if x[1]==0:\n",
    "         posNeg[x]=posNeg[x]/ totelNeg\n",
    "    else:\n",
    "         posNeg[x]= posNeg[x]/totelPos\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "f34d639b-7b54-4657-9065-7b408cf5f82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999994821\n"
     ]
    }
   ],
   "source": [
    "print(findTotel(posNeg,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "25f45e52-c840-4983-be97-07ffb6805543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making pridiction\n",
    "comment=[[\"i understood that the story was about cold\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "81000176-89c0-4741-873b-8cbe82c09e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=processData(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "9a5f1b19-5b96-41e7-90fb-a9c2e9af61b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mposNegfreq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      /tmp/ipykernel_39487/2669449510.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "posNegfreq?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "b94a7242-b6bd-4266-94d3-10877548ce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findprobIn(key,prob):\n",
    "    \n",
    "    if((key,0) in prob):\n",
    "        print(prob[(key,0)])\n",
    "    if((key,1) in prob):\n",
    "        print(prob[(key,1)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "76090683-b029-4244-b0a4-3ad8b5d6dec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['understood', 'stori', 'cold']\n",
      "3.935541878706599e-05\n",
      "4.3123197585100937e-05\n",
      "None\n",
      "0.002924410349869673\n",
      "0.0035684446001671023\n",
      "None\n",
      "0.00016044901505496135\n",
      "0.000253348785812468\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for row in data:\n",
    "    print(row)\n",
    "    for x in row:\n",
    "        print(findprobIn(x,posNeg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1729d384-1c26-4714-ac41-8f43263f62ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b27dd8-5974-463c-a11b-5ee98e86db2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e789bf6-3567-4faf-8359-1e187313922c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deef0bcd-6957-4cf0-a02a-805b959d9f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea31d10-780d-49a4-9d4d-e4b3bbf0cf52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1684a3f-89bf-4660-b5c5-e4bd52d476d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300a195d-55d1-48f2-b884-3215ac06cdc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb959db-7422-4b41-b36d-d36efc39b616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7848aa-8386-4d69-9620-d16f47bc013f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22de36e1-d555-484d-aea3-c971e1f49a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dda2a1-4765-4206-909d-04af83d3da63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec9c5c5-aacf-4c96-95b1-46ac44f3ede5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ed1ae1-9066-48a8-8c46-55c49a37593c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1df846-f0ad-4278-bc5d-814aa9f3269c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7850a86d-37d3-444b-9f2a-7440594b4778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ae7ce3-b110-4482-aeb6-e14fe1761d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea95bc4e-d9a1-4261-b026-bc20d01ba3c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c69b3ab-17c2-47d4-b6a0-63559edc6e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775d67d0-6274-4982-90cf-0cc6c4ee78f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad876a7a-6090-4fcf-b65f-865e0edfe994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70c8324-dcd1-4e58-9790-bc592a101cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe92ddd9-1039-42d5-a483-af4331f33d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5be8ff-a09c-496a-909b-f0b622aac911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
